{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c2d06b-3a5b-4bca-8a8b-62e1c9bc70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763df372-ab58-491c-bd9b-d46b90b5ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability of including 63% of data: 0.9955\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the size of the original dataset\n",
    "n = 10000  # You can change this to the size of your dataset\n",
    "\n",
    "# Number of Monte Carlo simulations\n",
    "num_simulations = 10000  # You can adjust this number\n",
    "\n",
    "# Initialize a count variable to keep track of the data points included\n",
    "count_included = 0\n",
    "\n",
    "# Perform Monte Carlo simulations\n",
    "for _ in range(num_simulations):\n",
    "    # Generate a random bootstrapped sample by sampling with replacement\n",
    "    bootstrap_sample = np.random.choice(range(n), size=n, replace=True)\n",
    "    \n",
    "    # Count the unique data points in the bootstrapped sample\n",
    "    unique_data_points_in_sample = len(np.unique(bootstrap_sample))\n",
    "    \n",
    "    # Calculate the percentage of unique data points in the sample\n",
    "    percentage_included = unique_data_points_in_sample / n\n",
    "    \n",
    "    # Add to the count if the percentage is close to 0.632 (63.2%)\n",
    "    if 0.62 <= percentage_included <= 0.64:\n",
    "        count_included += 1\n",
    "\n",
    "# Calculate the estimated probability of including about 63% of the data\n",
    "estimated_probability = count_included / num_simulations\n",
    "\n",
    "print(f\"Estimated probability of including 63% of data: {estimated_probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d1a95d-4b9a-4abe-87fc-dd5e088fed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with replace [1 4 0 0 9 5 8 1 5 5] by definition will have duplicates\n",
      "without replace [2 0 4 1 3 6 8 9 5 7]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "x = np.random.choice(range(n), size=n, replace=True)\n",
    "print(f\"with replace {x} by definition will have duplicates\")\n",
    "x = np.random.choice(range(n), size=n, replace=False)\n",
    "print(f\"without replace {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ef1782-14ae-41d0-a162-cc54f0df5aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.alphas = []\n",
    "        self.stumps = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        w = np.ones(m) / m  # Initialize sample weights\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            stump = self._fit_stump(X, y, w)\n",
    "            stump_error = self._stump_error(stump, X, y, w)\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            alpha = 0.5 * np.log((1 - stump_error) / max(stump_error, 1e-10))\n",
    "            \n",
    "            # Update sample weights\n",
    "            w *= np.exp(-alpha * y * stump.predict(X))\n",
    "            w /= np.sum(w)\n",
    "            \n",
    "            # Save alpha and stump\n",
    "            self.alphas.append(alpha)\n",
    "            self.stumps.append(stump)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        for alpha, stump in zip(self.alphas, self.stumps):\n",
    "            preds += alpha * stump.predict(X)\n",
    "        return np.sign(preds)\n",
    "    \n",
    "    def _fit_stump(self, X, y, w):\n",
    "        m, n = X.shape\n",
    "        best_stump = None\n",
    "        min_error = np.inf\n",
    "        \n",
    "        for feature in range(n):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            for value in unique_values:\n",
    "                for sign in [1, -1]:\n",
    "                    stump = Stump(feature, value, sign)\n",
    "                    error = self._stump_error(stump, X, y, w)\n",
    "                    \n",
    "                    if error < min_error:\n",
    "                        min_error = error\n",
    "                        best_stump = stump\n",
    "        \n",
    "        return best_stump\n",
    "    \n",
    "    def _stump_error(self, stump, X, y, w):\n",
    "        return np.sum(w * (stump.predict(X) != y))\n",
    "\n",
    "class Stump:\n",
    "    def __init__(self, feature, value, sign):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.sign = sign\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.sign * (X[:, self.feature] > self.value)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Generate a synthetic dataset\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "    \n",
    "    # Initialize and train AdaBoost\n",
    "    adaboost = AdaBoost(n_estimators=50)\n",
    "    adaboost.fit(X, y)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = adaboost.predict(X)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a5191-6764-414c-87a5-21ae241c8620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
