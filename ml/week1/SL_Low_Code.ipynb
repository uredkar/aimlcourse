{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbxzw7Ec-yX1"
      },
      "source": [
        "# Supervised Learning Classification Project: AllLife Bank Personal Loan Campaign"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement"
      ],
      "metadata": {
        "id": "yAQlihZSROPj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojPyumTZ-yX3"
      },
      "source": [
        "### Context\n",
        "\n",
        "AllLife Bank is a US bank that has a growing customer base. The majority of these customers are liability customers (depositors) with varying sizes of deposits. The number of customers who are also borrowers (asset customers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business and in the process, earn more through the interest on loans. In particular, the management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors).\n",
        "\n",
        "A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns with better target marketing to increase the success ratio.\n",
        "\n",
        "You as a Data scientist at AllLife bank have to build a model that will help the marketing department to identify the potential customers who have a higher probability of purchasing the loan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZyaD9La-yX4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "To predict whether a liability customer will buy personal loans, to understand which customer attributes are most significant in driving purchases, and identify which segment of customers to target more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-N6GP4--yX5"
      },
      "source": [
        "### Data Dictionary\n",
        "* `ID`: Customer ID\n",
        "* `Age`: Customerâ€™s age in completed years\n",
        "* `Experience`: #years of professional experience\n",
        "* `Income`: Annual income of the customer (in thousand dollars)\n",
        "* `ZIP Code`: Home Address ZIP code.\n",
        "* `Family`: the Family size of the customer\n",
        "* `CCAvg`: Average spending on credit cards per month (in thousand dollars)\n",
        "* `Education`: Education Level. 1: Undergrad; 2: Graduate;3: Advanced/Professional\n",
        "* `Mortgage`: Value of house mortgage if any. (in thousand dollars)\n",
        "* `Personal_Loan`: Did this customer accept the personal loan offered in the last campaign? (0: No, 1: Yes)\n",
        "* `Securities_Account`: Does the customer have securities account with the bank? (0: No, 1: Yes)\n",
        "* `CD_Account`: Does the customer have a certificate of deposit (CD) account with the bank? (0: No, 1: Yes)\n",
        "* `Online`: Do customers use internet banking facilities? (0: No, 1: Yes)\n",
        "* `CreditCard`: Does the customer use a credit card issued by any other Bank (excluding All life Bank)? (0: No, 1: Yes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Please read the instructions carefully before starting the project.** \n",
        "\n",
        "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned. \n",
        "* Blanks '_______' are provided in the notebook that \n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space. \n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same."
      ],
      "metadata": {
        "id": "i2OaKCmZ-4iX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuvei8I7-yX7"
      },
      "source": [
        "## Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAZsT0Ii-yX_",
        "outputId": "414e7933-cbdc-4d27-ec1a-0801427bfa62"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 1;\n",
              "                var nbb_unformatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Libraries to help with reading and manipulating data\\n\\nimport pandas as pd\\nimport numpy as np\\n\\n# Library to split data\\nfrom sklearn.model_selection import train_test_split\\n\\n# libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Removes the limit for the number of displayed columns\\npd.set_option(\\\"display.max_columns\\\", None)\\n# Sets the limit for the number of displayed rows\\npd.set_option(\\\"display.max_rows\\\", 200)\\n\\n\\n# To build model for prediction\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn import tree\\n\\n# To tune different models\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# To get diferent metric scores\\n\\n\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n    precision_recall_curve,\\n    roc_curve,\\n    make_scorer,\\n)\";\n",
              "                var nbb_formatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Libraries to help with reading and manipulating data\\n\\nimport pandas as pd\\nimport numpy as np\\n\\n# Library to split data\\nfrom sklearn.model_selection import train_test_split\\n\\n# libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Removes the limit for the number of displayed columns\\npd.set_option(\\\"display.max_columns\\\", None)\\n# Sets the limit for the number of displayed rows\\npd.set_option(\\\"display.max_rows\\\", 200)\\n\\n\\n# To build model for prediction\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn import tree\\n\\n# To tune different models\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# To get diferent metric scores\\n\\n\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n    precision_recall_curve,\\n    roc_curve,\\n    make_scorer,\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# this will help in making the Python code more structured automatically (good coding practice)\n",
        "%load_ext nb_black\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Library to split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n",
        "\n",
        "# To build model for prediction\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "# To tune different models\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# To get diferent metric scores\n",
        "\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    plot_confusion_matrix,\n",
        "    precision_recall_curve,\n",
        "    roc_curve,\n",
        "    make_scorer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-Qu_8Ez-yYG"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Loan = pd.read_csv(\"_________________\") ##  Complete the code to read the data"
      ],
      "metadata": {
        "id": "CC6Sh8HX-_wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7CCfEWF-yYI",
        "outputId": "7bc0954a-8a71-458d-a6e3-0545f9be095a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 4;\n",
              "                var nbb_unformatted_code = \"# copying data to another variable to avoid any changes to original data\\ndata = Loan.copy()\";\n",
              "                var nbb_formatted_code = \"# copying data to another variable to avoid any changes to original data\\ndata = Loan.copy()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# copying data to another variable to avoid any changes to original data\n",
        "data = Loan.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Overview"
      ],
      "metadata": {
        "id": "C-yIAecVQT4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initial steps to get an overview of any dataset is to: \n",
        "- Observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- Get information about the number of rows and columns in the dataset\n",
        "- Find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- Check the statistical summary of the dataset to get an overview of the numerical columns of the data"
      ],
      "metadata": {
        "id": "xlXirq1nQQOA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UuhpOqt-yYJ"
      },
      "source": [
        "### View the first and last 5 rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.'_______' ##  Complete the code to view top 5 rows of the data"
      ],
      "metadata": {
        "id": "wWfYU9h5_HwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.'_______' ##  Complete the code to view last 5 rows of the data "
      ],
      "metadata": {
        "id": "lLhloWys_Jed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEuSu6e4hU2e"
      },
      "source": [
        "### Understand the shape of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.'_______' ##  Complete the code to view dimensions of the data"
      ],
      "metadata": {
        "id": "d_3SH2GB_LvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwAu-vEwhU2m"
      },
      "source": [
        "### Check the data types of the columns for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "J5WUtD0u_WT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Statistical Summary"
      ],
      "metadata": {
        "id": "qV74PSIGTb3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe().T  ## Complete the code to get the statistical summary of the data"
      ],
      "metadata": {
        "id": "K72sl_IZzydx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's drop the Booking_ID column first before we proceed forward"
      ],
      "metadata": {
        "id": "CuKKXkhq_nFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.'_________' ## Complete the code to drop the ID column from the dataframe "
      ],
      "metadata": {
        "id": "zwTS8fRf_fNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "5feS0OZJVA0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for Anomalous Values"
      ],
      "metadata": {
        "id": "1--9NsTeVEIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKCYLk4B-yYT"
      },
      "outputs": [],
      "source": [
        "# Let's map the values to 1: Undergrad; 2: Graduate 3: Advanced/Professional\n",
        "data[\"Education\"].replace(1, \"Undergraduate\", inplace=True)\n",
        "data[\"Education\"].replace(2, \"Graduate\", inplace=True)\n",
        "data[\"Education\"].replace(3, \"Professional\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ4IJDuT-yYU"
      },
      "source": [
        "\n",
        "* Treating the negative values of Experience: We assume that these negative signs here are data input errors, so we will replace them with positive signs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kduoxUMO-yYU"
      },
      "outputs": [],
      "source": [
        "# checking if experience <0\n",
        "data[data[\"Experience\"] < 0][\"Experience\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NaikQGP-yYV"
      },
      "outputs": [],
      "source": [
        "# Correcting the experience values\n",
        "data[\"Experience\"].replace(-1, 1, inplace=True)\n",
        "data[\"Experience\"].replace(-2, 2, inplace=True)\n",
        "data[\"Experience\"].replace(-3, 3, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "MGmJyKt6VST0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrM8-hC5-yYV"
      },
      "outputs": [],
      "source": [
        "# checking the number of uniques in the zip code\n",
        "data[\"ZIPCode\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG18Z9rE-yYW"
      },
      "outputs": [],
      "source": [
        "data[\"ZIPCode\"] = data[\"ZIPCode\"].astype(str)\n",
        "print(\n",
        "    \"Number of unique values if we take first two digits of ZIPCode: \",\n",
        "    data[\"ZIPCode\"].str[0:2].nunique(),\n",
        ")\n",
        "data[\"ZIPCode\"] = data[\"ZIPCode\"].str[0:2]\n",
        "\n",
        "data[\"ZIPCode\"] = data[\"ZIPCode\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNj5WYef-yYW"
      },
      "outputs": [],
      "source": [
        "## Converting the data type of categorical features to 'category'\n",
        "cat_cols = [\n",
        "    \"Education\",\n",
        "    \"Personal_Loan\",\n",
        "    \"Securities_Account\",\n",
        "    \"CD_Account\",\n",
        "    \"Online\",\n",
        "    \"CreditCard\",\n",
        "    \"ZIPCode\",\n",
        "]\n",
        "data[cat_cols] = data[cat_cols].astype(\"_______\")    # Complete the code to convert the cat_cols to category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1KZfbwv-yYP"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate Analysis"
      ],
      "metadata": {
        "id": "4vJzUjS9_-Jt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef-2oS7z-yYP",
        "outputId": "fba4db73-eec3-4acb-c911-8856214f228f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 9;\n",
              "                var nbb_unformatted_code = \"def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to show the density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\";\n",
              "                var nbb_formatted_code = \"def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to show the density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to show the density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O72HDsfS-yYQ"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Age"
      ],
      "metadata": {
        "id": "QjuGWeOmEGoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data, \"age\")"
      ],
      "metadata": {
        "id": "LnCq2WEpDou5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Experience"
      ],
      "metadata": {
        "id": "zzdrcVHaEY0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot('____________') ## Complete the code to create histogram_boxplot for experience"
      ],
      "metadata": {
        "id": "DY3N62KZDosK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Income"
      ],
      "metadata": {
        "id": "24eVdJLlEkEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot('_______________')  ## Complete the code to create histogram_boxplot for Income"
      ],
      "metadata": {
        "id": "7bZMRP1GDopX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on CCAvg"
      ],
      "metadata": {
        "id": "DG4dgxL_ExDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot('_______________')  ## Complete the code to create histogram_boxplot for CCAvg"
      ],
      "metadata": {
        "id": "10ElzFKwDomo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Mortgage"
      ],
      "metadata": {
        "id": "a0GLlhKCE5bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot('_______________')  ## Complete the code to create histogram_boxplot for Mortgage"
      ],
      "metadata": {
        "id": "mCij70gSDoju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Family "
      ],
      "metadata": {
        "id": "JzTJoVRME-fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Family\", perc=True) "
      ],
      "metadata": {
        "id": "1VQnJ5JRDogq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Education"
      ],
      "metadata": {
        "id": "5v-RI3_hFHKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot('_______')   ## Complete the code to create labeled_barplot for Education"
      ],
      "metadata": {
        "id": "h0GPe7cnDodZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Securities_Account"
      ],
      "metadata": {
        "id": "iu38TAwRFUb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot('_______')   ## Complete the code to create labeled_barplot for Securities_Account"
      ],
      "metadata": {
        "id": "XdOetrRMFSeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on CD_Account"
      ],
      "metadata": {
        "id": "itZOMUhcFcao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot('_______')   ## Complete the code to create labeled_barplot for CD_Account"
      ],
      "metadata": {
        "id": "78Ds-L7ZFSbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations on Online"
      ],
      "metadata": {
        "id": "BdeJ6JQFFjW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot('_______')   ## Complete the code to create labeled_barplot for Online"
      ],
      "metadata": {
        "id": "CQKSU3CHFSYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observation on CreditCard"
      ],
      "metadata": {
        "id": "PdzxuDEaFmbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot('_______')   ## Complete the code to create labeled_barplot for CreditCard"
      ],
      "metadata": {
        "id": "xQq2aLT0FSVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observation on ZIPCode"
      ],
      "metadata": {
        "id": "ACJO6FE1F5Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot('_______')   ## Complete the code to create labeled_barplot for ZIPCode"
      ],
      "metadata": {
        "id": "893IZRDaF4_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bivariate Analysis"
      ],
      "metadata": {
        "id": "6ocQdtn6F8Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacked_barplot(data, predictor, target):\n",
        "    \"\"\"\n",
        "    Print the category counts and plot a stacked bar chart\n",
        "\n",
        "    data: dataframe\n",
        "    predictor: independent variable\n",
        "    target: target variable\n",
        "    \"\"\"\n",
        "    count = data[predictor].nunique()\n",
        "    sorter = data[target].value_counts().index[-1]\n",
        "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
        "        by=sorter, ascending=False\n",
        "    )\n",
        "    print(tab1)\n",
        "    print(\"-\" * 120)\n",
        "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
        "        by=sorter, ascending=False\n",
        "    )\n",
        "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 5))\n",
        "    plt.legend(\n",
        "        loc=\"lower left\", frameon=False,\n",
        "    )\n",
        "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-6XVBRj5Q1_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### function to plot distributions wrt target\n",
        "\n",
        "\n",
        "def distribution_plot_wrt_target(data, predictor, target):\n",
        "\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    target_uniq = data[target].unique()\n",
        "\n",
        "    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n",
        "    sns.histplot(\n",
        "        data=data[data[target] == target_uniq[0]],\n",
        "        x=predictor,\n",
        "        kde=True,\n",
        "        ax=axs[0, 0],\n",
        "        color=\"teal\",\n",
        "        stat=\"density\",\n",
        "    )\n",
        "\n",
        "    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n",
        "    sns.histplot(\n",
        "        data=data[data[target] == target_uniq[1]],\n",
        "        x=predictor,\n",
        "        kde=True,\n",
        "        ax=axs[0, 1],\n",
        "        color=\"orange\",\n",
        "        stat=\"density\",\n",
        "    )\n",
        "\n",
        "    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n",
        "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n",
        "\n",
        "    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n",
        "    sns.boxplot(\n",
        "        data=data,\n",
        "        x=target,\n",
        "        y=predictor,\n",
        "        ax=axs[1, 1],\n",
        "        showfliers=False,\n",
        "        palette=\"gist_rainbow\",\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "g5fOGMviQ21L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation check"
      ],
      "metadata": {
        "id": "GOXF6qiVZ1jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "sns.heatmap(______.corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\") # Complete the code to get the heatmap of the data\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roJ_-HU2GEeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's check how a customer's interest in purchasing a loan varies with their education"
      ],
      "metadata": {
        "id": "IOp9K2wEG5p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(data, \"Education\", \"Personal_Loan\")"
      ],
      "metadata": {
        "id": "p82CWckFGEbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal_Loan vs Family"
      ],
      "metadata": {
        "id": "soQXBsZNG8Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(\"________________________\")  ## Complete the code to plot stacked barplot for Personal Loan and Family"
      ],
      "metadata": {
        "id": "w1jvdwNMGEY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal_Loan vs Securities_Account"
      ],
      "metadata": {
        "id": "BgOQfs9_HBej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(\"________________________\") ## Complete the code to plot stacked barplot for Personal Loan and Securities_Account"
      ],
      "metadata": {
        "id": "HVuBG7AQFSSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal_Loan vs CD_Account"
      ],
      "metadata": {
        "id": "WyLpV-BRHPkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(\"________________________\") ## Complete the code to plot stacked barplot for Personal Loan and CD_Account"
      ],
      "metadata": {
        "id": "FeIX0THcHNN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal_Loan vs Online"
      ],
      "metadata": {
        "id": "OGv86aejHTG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(\"________________________\") ## Complete the code to plot stacked barplot for Personal Loan and Online"
      ],
      "metadata": {
        "id": "ne8p8nukHNLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal_Loan vs CreditCard"
      ],
      "metadata": {
        "id": "a9nCniQgHZUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(\"________________________\") ## Complete the code to plot stacked barplot for Personal Loan and CreditCard"
      ],
      "metadata": {
        "id": "FkE6UfOdHXUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal_Loan vs ZIPCode"
      ],
      "metadata": {
        "id": "0YcmISkyHc_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_barplot(\"________________________\") ## Complete the code to plot stacked barplot for Personal Loan and ZIPCode"
      ],
      "metadata": {
        "id": "5SGyq83jHXR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's check how a customer's interest in purchasing a loan varies with their age"
      ],
      "metadata": {
        "id": "CO30h257HiLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_plot_wrt_target(data, \"Age\", \"Personal_Loan\") "
      ],
      "metadata": {
        "id": "hYAGce0aHh3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal Loan vs Experience"
      ],
      "metadata": {
        "id": "wu6IjYeVHyEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_plot_wrt_target(\"_____________________\") ## Complete the code to plot stacked barplot for Personal Loan and Experience"
      ],
      "metadata": {
        "id": "-Hdu4YUMHNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal Loan vs Income"
      ],
      "metadata": {
        "id": "Zl2-uHxAH_CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_plot_wrt_target(\"_____________________\") ## Complete the code to plot stacked barplot for Personal Loan and Income"
      ],
      "metadata": {
        "id": "ktZUooaVH9Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personal Loan vs CCAvg"
      ],
      "metadata": {
        "id": "kIdGE5OZIGuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_plot_wrt_target(\"_____________________\") ## Complete the code to plot stacked barplot for Personal Loan and CCAvg"
      ],
      "metadata": {
        "id": "daHESc6fH9G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing (contd.)"
      ],
      "metadata": {
        "id": "W8_oyQN4UpGN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6qc_U-V-yYX"
      },
      "source": [
        "### Outlier Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkUVaJus-yYY"
      },
      "outputs": [],
      "source": [
        "Q1 = data.quantile(______)  # Complete the code to find the 25th percentile and 75th percentile.\n",
        "Q3 = data.quantile(______)  # Complete the code to find the 75th percentile and 75th percentile.\n",
        "\n",
        "IQR = Q3 - Q1               # Inter Quantile Range (75th perentile - 25th percentile)\n",
        "\n",
        "lower = Q1 - 1.5 * IQR  # Finding lower and upper bounds for all values. All values outside these bounds are outliers\n",
        "upper = Q3 + 1.5 * IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwap_wWC-yYY"
      },
      "outputs": [],
      "source": [
        "((data.select_dtypes(include=[\"float64\", \"int64\"]) < lower)\n",
        "    |(data.select_dtypes(include=[\"float64\", \"int64\"]) > upper)\n",
        ").sum() / len(data) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH7q0NZs-yYf"
      },
      "source": [
        "### Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The objective is to predict whether a liability customer will buy personal loans.\n",
        "- Before you proceed to build a model, you need to split the data into train, test and validation to be able to evaluate the model that you build on the train data\n",
        "- You'll have to encode categorical features and scale numerical values.\n",
        "- You will build a model using the train data and then check it's performance"
      ],
      "metadata": {
        "id": "2uHUW2q9SUyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate independent and dependent variable\n",
        "X = data.drop([\"Personal_Loan\", \"Experience\"], axis=1)\n",
        "Y = data[\"Personal_Loan\"]"
      ],
      "metadata": {
        "id": "8QElbfhhIs9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dls7C3lJ-yYf"
      },
      "outputs": [],
      "source": [
        "# Complete the code to apply dummies on ZIPCode and Education\n",
        "X = pd.get_dummies(X, columns=[\"______\", \"_____\"], drop_first=True)  \n",
        "\n",
        "# Complete the code to split data in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(_____, _____, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F10PvB3R-yYg"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of Training set : \", __________.shape)     # Complete the code to get the shape of train data\n",
        "print(\"Shape of test set : \", ________.shape)           # Complete the code to get the shape of test data\n",
        "print(\"Percentage of classes in training set:\")\n",
        "print(______.value_counts(normalize=True))              # Complete the code to get the value counts of y train data\n",
        "print(\"Percentage of classes in test set:\")\n",
        "print(_________.value_counts(normalize=True))           # Complete the code to get the value counts of y test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymY_llr6-yYg"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV-MWTcL-yYg"
      },
      "source": [
        "### Model Evaluation Criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model can make wrong predictions as:**\n",
        "\n",
        "1. Predicting a customer will take the personal loan but in reality the customer will not take the personal loan - Loss of resources\n",
        "2. Predicting a customer will not take the personal loan but in reality the customer was going to take the personal loan - Loss of opportunity\n",
        "\n",
        "**Which case is more important?**\n",
        "* Losing a potential customer by predicting that the customer will not be taking the personal loan but in reality the customer was going to take the personal loan.\n",
        "\n",
        "**How to reduce this loss i.e need to reduce False Negatives?**\n",
        "\n",
        "* Bank would want `Recall` to be maximized, greater the Recall higher the chances of minimizing false negatives. Hence, the focus should be on increasing Recall or minimizing the false negatives."
      ],
      "metadata": {
        "id": "AEiw4nTDVgTQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOcpLC-k-yYh"
      },
      "source": [
        "First, let's create functions to calculate different metrics and confusion matrix so that we don't have to use the same code repeatedly for each model.\n",
        "* The model_performance_classification_sklearn_with_threshold function will be used to check the model performance of models. \n",
        "* The confusion_matrix_sklearn_with_threshold function will be used to plot confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6FN_74m-yYv"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_PN55S_-yYv"
      },
      "source": [
        "First, let's create functions to calculate different metrics and confusion matrix so that we don't have to use the same code repeatedly for each model.\n",
        "\n",
        "* The model_performance_classification_sklearn function will be used to check the model performance of models. \n",
        "* The confusion_matrix_sklearnfunction will be used to plot confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb1x1mZm-yYv"
      },
      "outputs": [],
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "def model_performance_classification_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WojMLqDE-yYv"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(predictors)\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(2, 2)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJXZc_JZ-yYw"
      },
      "source": [
        "#### Build Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12p4gmgn-yYw"
      },
      "outputs": [],
      "source": [
        "# Initialize the Decision Tree Classifier\n",
        "model = DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
        "model.fit(\"___________\")  ## Complete the code to fit decision tree on train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ibri4Bf-yYw"
      },
      "source": [
        "#### Checking model performance on training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec8e_FKW-yYx"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_sklearn(model, X_train, y_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98B52akv-yYx"
      },
      "outputs": [],
      "source": [
        "decision_tree_perf_train = model_performance_classification_sklearn(model, X_train, y_train)\n",
        "decision_tree_perf_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw3fFVGU-yYx"
      },
      "source": [
        "#### Visualizing the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMHTT5fM-yYy"
      },
      "outputs": [],
      "source": [
        "feature_names = list(X_train.columns)\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2dvgK2Z-yYy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 30))\n",
        "out = tree.plot_tree(\n",
        "    model,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,\n",
        "    fontsize=9,\n",
        "    node_ids=False,\n",
        "    class_names=None,\n",
        ")\n",
        "# below code will add arrows to the decision tree split if they are missing\n",
        "for o in out:\n",
        "    arrow = o.arrow_patch\n",
        "    if arrow is not None:\n",
        "        arrow.set_edgecolor(\"black\")\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkn1Vp9j-yYy"
      },
      "outputs": [],
      "source": [
        "# Text report showing the rules of a decision tree -\n",
        "\n",
        "print(tree.export_text(model, feature_names=feature_names, show_weights=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZyoMffO-yYz"
      },
      "outputs": [],
      "source": [
        "# importance of features in the tree building ( The importance of a feature is computed as the\n",
        "# (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
        "\n",
        "print(\n",
        "    pd.DataFrame(\n",
        "        model.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n",
        "    ).sort_values(by=\"Imp\", ascending=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e0PeNRX-yYz"
      },
      "outputs": [],
      "source": [
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking model performance on test data"
      ],
      "metadata": {
        "id": "zMOPpBD3ab0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_sklearn(\"_____________\")  # Complete the code to get the confusion matrix for test data"
      ],
      "metadata": {
        "id": "CfjfI2z8acgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code to get the model formance on test data\n",
        "decision_tree_perf_test = model_performance_classification_sklearn(\"_________________\")\n",
        "decision_tree_perf_test"
      ],
      "metadata": {
        "id": "t6xaz89Xacbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7whm5B4e-yY0"
      },
      "source": [
        "### Model Performance Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO8T_3p2-yY0"
      },
      "source": [
        "#### Pre-Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fp_gE4J-yY0"
      },
      "outputs": [],
      "source": [
        "# Choose the type of classifier.\n",
        "estimator = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"max_depth\": np.arange(6, 15),\n",
        "    \"min_samples_leaf\": [1, 2, 5, 7, 10],\n",
        "    \"max_leaf_nodes\": [2, 3, 5, 10],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "acc_scorer = make_scorer(recall_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(estimator, parameters, scoring=acc_scorer, cv=5)\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "estimator = grid_obj.best_estimator_\n",
        "\n",
        "estimator.fit(\"______________\") ## Complete the code to fit model on train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USChR4oJ-yY1"
      },
      "source": [
        "**Checking performance on training data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu166dcK-yY1"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_sklearn(___________________) ## Complete the code to create confusion matrix for train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8pSIDso-yY1"
      },
      "outputs": [],
      "source": [
        "decision_tree_tune_perf_train = model_performance_classification_sklearn(______________) ## Complete the code to check performance on train data\n",
        "decision_tree_tune_perf_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBJivnrU-yY1"
      },
      "source": [
        "**Visualizing the Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOqcAwv0-yY2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "out = tree.plot_tree(\n",
        "    estimator,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,\n",
        "    fontsize=9,\n",
        "    node_ids=False,\n",
        "    class_names=None,\n",
        ")\n",
        "# below code will add arrows to the decision tree split if they are missing\n",
        "for o in out:\n",
        "    arrow = o.arrow_patch\n",
        "    if arrow is not None:\n",
        "        arrow.set_edgecolor(\"black\")\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00GnX841-yY2"
      },
      "outputs": [],
      "source": [
        "# Text report showing the rules of a decision tree -\n",
        "\n",
        "print(tree.export_text(estimator, feature_names=feature_names, show_weights=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdIqKlBv-yY3"
      },
      "outputs": [],
      "source": [
        "# importance of features in the tree building ( The importance of a feature is computed as the\n",
        "# (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
        "\n",
        "print(\n",
        "    pd.DataFrame(\n",
        "        estimator.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n",
        "    ).sort_values(by=\"Imp\", ascending=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oirjtU5R-yY3"
      },
      "outputs": [],
      "source": [
        "importances = estimator.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking performance on test data**"
      ],
      "metadata": {
        "id": "BdtwBRzKa0AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_sklearn(\"___________\")  # Complete the code to get the confusion matrix on test data"
      ],
      "metadata": {
        "id": "BP_DajD2a0i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code to get the model performance on test data\n",
        "decision_tree_tune_perf_test = model_performance_classification_sklearn(\"_________________\")\n",
        "decision_tree_tune_perf_test"
      ],
      "metadata": {
        "id": "_3bzBiWIa0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y90VzluQ-yY4"
      },
      "source": [
        "#### Cost-Complexity Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBrWql6O-yY4"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier(random_state=1)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFRgLSNW-yY5"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wN8MOeT-yY5"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
        "ax.set_xlabel(\"effective alpha\")\n",
        "ax.set_ylabel(\"total impurity of leaves\")\n",
        "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pxGBtUh-yY5"
      },
      "source": [
        "Next, we train a decision tree using effective alphas. The last value\n",
        "in ``ccp_alphas`` is the alpha value that prunes the whole tree,\n",
        "leaving the tree, ``clfs[-1]``, with one node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cLhDN8n-yY6"
      },
      "outputs": [],
      "source": [
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=1, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(__________)     ## Complete the code to fit decision tree on training data\n",
        "    clfs.append(clf)\n",
        "print(\n",
        "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
        "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNenQrMM-yY6"
      },
      "outputs": [],
      "source": [
        "clfs = clfs[:-1]\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "node_counts = [clf.tree_.node_count for clf in clfs]\n",
        "depth = [clf.tree_.max_depth for clf in clfs]\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 7))\n",
        "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
        "ax[0].set_xlabel(\"alpha\")\n",
        "ax[0].set_ylabel(\"number of nodes\")\n",
        "ax[0].set_title(\"Number of nodes vs alpha\")\n",
        "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
        "ax[1].set_xlabel(\"alpha\")\n",
        "ax[1].set_ylabel(\"depth of tree\")\n",
        "ax[1].set_title(\"Depth vs alpha\")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiovyRZL-yY6"
      },
      "source": [
        "**Recall vs alpha for training and testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g_S43Vp-yY7"
      },
      "outputs": [],
      "source": [
        "recall_train = []\n",
        "for clf in clfs:\n",
        "    pred_train = clf.predict(X_train)\n",
        "    values_train = recall_score(y_train, pred_train)\n",
        "    recall_train.append(values_train)\n",
        "\n",
        "recall_test = []\n",
        "for clf in clfs:\n",
        "    pred_test = clf.predict(X_test)\n",
        "    values_test = recall_score(y_test, pred_test)\n",
        "    recall_test.append(values_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e3ZFo4e-yY7"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"Recall\")\n",
        "ax.set_title(\"Recall vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas, recall_train, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
        "ax.plot(ccp_alphas, recall_test, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciM8wQM6-yY7"
      },
      "outputs": [],
      "source": [
        "index_best_model = np.argmax(recall_test)\n",
        "best_model = clfs[index_best_model]\n",
        "print(best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Post-Purning"
      ],
      "metadata": {
        "id": "TiEyQuexJi6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator_2 = DecisionTreeClassifier(\n",
        "    ccp_alpha='__________', class_weight={0: 0.15, 1: 0.85}, random_state=1         ## Complete the code by adding the correct ccp_alpha value\n",
        ")\n",
        "estimator_2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lqVMIBGkJYvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking performance on training data**"
      ],
      "metadata": {
        "id": "teC2sBIqJ-aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_sklearn(___________________) ## Complete the code to create confusion matrix for train data"
      ],
      "metadata": {
        "id": "PnyDmQfdJYqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree_tune_post_train = model_performance_classification_sklearn(______________) ## Complete the code to check performance on train data\n",
        "decision_tree_tune_post_train"
      ],
      "metadata": {
        "id": "TLCU4D4pJYmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing the Decision Tree**"
      ],
      "metadata": {
        "id": "8E29ajQJKIIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "out = tree.plot_tree(\n",
        "    estimator_2,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,\n",
        "    fontsize=9,\n",
        "    node_ids=False,\n",
        "    class_names=None,\n",
        ")\n",
        "# below code will add arrows to the decision tree split if they are missing\n",
        "for o in out:\n",
        "    arrow = o.arrow_patch\n",
        "    if arrow is not None:\n",
        "        arrow.set_edgecolor(\"black\")\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zV5WX9U-JYh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text report showing the rules of a decision tree -\n",
        "\n",
        "print(tree.export_text(estimator_2, feature_names=feature_names, show_weights=True))"
      ],
      "metadata": {
        "id": "iKXV-lgTJYdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importance of features in the tree building ( The importance of a feature is computed as the\n",
        "# (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
        "\n",
        "print(\n",
        "    pd.DataFrame(\n",
        "        estimator_2.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n",
        "    ).sort_values(by=\"Imp\", ascending=False)\n",
        ")"
      ],
      "metadata": {
        "id": "RqT520tJJW8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = estimator_2.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ns3WjdzTMMqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking performance on test data**"
      ],
      "metadata": {
        "id": "k51seI8KMQ_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_sklearn(\"___________\")  # Complete the code to get the confusion matrix on test data"
      ],
      "metadata": {
        "id": "GCfZQpWqMMk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code to get the model performance on test data\n",
        "decision_tree_tune_post_test = model_performance_classification_sklearn(\"_________________\")\n",
        "decision_tree_tune_post_test"
      ],
      "metadata": {
        "id": "G7ID5wFtMWTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klv7zdtk-yY-"
      },
      "source": [
        "## Model Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqFBZFHs-yY-"
      },
      "outputs": [],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [decision_tree_perf_train.T, decision_tree_tune_perf_train.T,decision_tree_tune_post_train.T], axis=1,\n",
        ")\n",
        "models_train_comp_df.columns = [\"Decision Tree sklearn\", \"Decision Tree (Pre-Pruning)\",\"Decision Tree (Post-Pruning)\"]\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1F7O72k-yY_"
      },
      "outputs": [],
      "source": [
        "# testing performance comparison\n",
        "\n",
        "'_______' ## Complete the code to compare performance of test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8bT6tsw-yZA"
      },
      "source": [
        "## Actionable Insights and Business Recommendations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What recommedations would you suggest to the bank?**"
      ],
      "metadata": {
        "id": "LAIsnkyTYmx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* \n"
      ],
      "metadata": {
        "id": "JAi7b4HnYp_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "meolQkWtYni4"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yAQlihZSROPj",
        "zuvei8I7-yX7",
        "x-Qu_8Ez-yYG",
        "C-yIAecVQT4x",
        "9UuhpOqt-yYJ",
        "dEuSu6e4hU2e",
        "mwAu-vEwhU2m",
        "qV74PSIGTb3V",
        "CuKKXkhq_nFj",
        "5feS0OZJVA0Q",
        "1--9NsTeVEIV",
        "MGmJyKt6VST0",
        "w1KZfbwv-yYP",
        "4vJzUjS9_-Jt",
        "QjuGWeOmEGoS",
        "zzdrcVHaEY0t",
        "24eVdJLlEkEU",
        "DG4dgxL_ExDR",
        "a0GLlhKCE5bg",
        "JzTJoVRME-fU",
        "5v-RI3_hFHKR",
        "iu38TAwRFUb5",
        "itZOMUhcFcao",
        "BdeJ6JQFFjW7",
        "PdzxuDEaFmbu",
        "ACJO6FE1F5Rk",
        "6ocQdtn6F8Uc",
        "GOXF6qiVZ1jD",
        "IOp9K2wEG5p0",
        "soQXBsZNG8Hc",
        "BgOQfs9_HBej",
        "WyLpV-BRHPkR",
        "OGv86aejHTG0",
        "a9nCniQgHZUu",
        "0YcmISkyHc_a",
        "CO30h257HiLq",
        "wu6IjYeVHyEj",
        "Zl2-uHxAH_CB",
        "kIdGE5OZIGuM",
        "W8_oyQN4UpGN",
        "f6qc_U-V-yYX",
        "EH7q0NZs-yYf",
        "kV-MWTcL-yYg",
        "h6FN_74m-yYv",
        "MJXZc_JZ-yYw",
        "3Ibri4Bf-yYw",
        "tw3fFVGU-yYx",
        "zMOPpBD3ab0x",
        "wO8T_3p2-yY0",
        "y90VzluQ-yY4",
        "Klv7zdtk-yY-",
        "y8bT6tsw-yZA"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}